{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187945bf-26a3-4a74-83fb-6a44c47130fa",
   "metadata": {},
   "source": [
    "# Object Detection with YOLOv8\n",
    "\n",
    "## Installation\n",
    "https://docs.ultralytics.com/quickstart/\n",
    " * pip install ultralytics\n",
    "\n",
    "## Custom Dataset\n",
    "학습을 위해서는 training, validation, testing으로 데이터를 분리해서 이미지와 라벨로 구성해야 합니다. \n",
    "\n",
    "이를 위해서 폴더 구성을 train, valid, test로 만들고 각각 폴더 아래에 images, labels라는 폴더를 만들고 이름을 공유하는 이미지와 라벨 파일을 넣어줍니다. (예, 1.png, 1.txt)\n",
    "\n",
    "data.yaml 파일을 만들어서 폴더 구성과 클래스 갯수, 클래스 이름 정보를 넣어줍니다. \n",
    "\n",
    "```\n",
    "train: /home/etri04/work/Pseudanabaena/train/images\n",
    "val: /home/etri04/work/Pseudanabaena/valid/images\n",
    "test: /home/etri04/work/Pseudanabaena/test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['pseudanabaena']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ca652f-49e5-415c-a559-c80e1b4ee007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4db61e-9fa2-4c23-90de-a00505c1a0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nonzero_files(folder_path):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if os.path.isfile(file_path) and os.path.getsize(file_path) > 0:\n",
    "                file_list.append(file_path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76001150-318c-462c-a626-03fb987dbeda",
   "metadata": {},
   "source": [
    "## 학습을 위한 이미지 가공\n",
    "Prediction 단계에서는 이미지의 크기는 무관하지만 학습을 위해서는 이미지 사이즈를 통일해야 한다. batch를 위해서는 이미지 사이즈가 같아야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e4c587-c1b9-4f48-8e51-c06fff8fa497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_files = get_nonzero_files('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d363c333-dc9b-4c11-8f0e-0c75ea270980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in image_files:\n",
    "    image = cv2.imread(i, cv2.IMREAD_ANYCOLOR)\n",
    "    image =cv2.resize(image, (640,640))\n",
    "    cv2.imwrite(i, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df401939-212d-4224-a462-3b6b8374873b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in image_files:\n",
    "    image = cv2.imread(i, 0)\n",
    "    # image =cv2.resize(image, (640,640))\n",
    "    cv2.imwrite(i, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad14095-72a5-44e0-bd08-66af2d22b6a5",
   "metadata": {},
   "source": [
    "## Data Augumentation \n",
    "학습 데이터를 눌리기 위해서 간단한 데이터 어그멘테이션을 진행했습니다. \n",
    "\n",
    "이 데이터셋의 경우 회전에 대해서 안전하기 때문에 90도씩 회전하면서 학습에 사용할 이미지 데이터를 얻었습니다. \n",
    "\n",
    "이미지를 회전하면 annotation 정보도 회정해야 하기 때문에 아래 rotate_yolo_labels_90()함수를 사용해서 annotation 정보도 회전 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9188b14-f0f8-4b86-a931-03cb35f0b6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotate_yolo_labels_90(yolo_labels_path, img_width, img_height):\n",
    "    with open(yolo_labels_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    rotated_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        class_idx, x_center_norm, y_center_norm, width_norm, height_norm = map(float, line.split())\n",
    "        class_idx = int(class_idx)\n",
    "\n",
    "        # Convert normalized center coordinates to pixel coordinates\n",
    "        x_center = x_center_norm * img_width\n",
    "        y_center = y_center_norm * img_height\n",
    "\n",
    "        # Compute new pixel coordinates for rotated bounding box\n",
    "        x_new = y_center\n",
    "        y_new = img_width - x_center\n",
    "        width_new = height_norm * img_height\n",
    "        height_new = width_norm * img_width\n",
    "\n",
    "        # Convert new pixel coordinates back to normalized coordinates\n",
    "        x_new_norm = x_new / img_height\n",
    "        y_new_norm = y_new / img_width\n",
    "        width_new_norm = width_new / img_height\n",
    "        height_new_norm = height_new / img_width\n",
    "\n",
    "        # Append rotated annotation to list of strings\n",
    "        rotated_line = f\"{class_idx} {x_new_norm:.6f} {y_new_norm:.6f} {width_new_norm:.6f} {height_new_norm:.6f}\\n\"\n",
    "        rotated_lines.append(rotated_line)\n",
    "\n",
    "    return rotated_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41256f-baed-4b28-94aa-83f868973d04",
   "metadata": {},
   "source": [
    "### 회전할 yolo dataset 정보\n",
    "이미지와 라벨 파일을 하나의 튜플로 묶어서 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f9e05ac-9a34-4328-8ba0-283a5f099cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"./valid_0/\"\n",
    "i = os.listdir(root+\"images/\")\n",
    "l = os.listdir(root+\"labels/\")\n",
    "\n",
    "i.sort()\n",
    "l.sort()\n",
    "dataset = [(root + \"images/\" + a, root + \"labels/\" + b) for a,b in zip(i,l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3bb23-ccb7-43f7-9df7-097be090fed1",
   "metadata": {},
   "source": [
    "동일한 경로와 이름을 사용하고 회전된 이미지와 라벨에는 r를 붙여 표시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c2ec85-2253-42ec-aa9d-a75812d8dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in dataset:\n",
    "    img_name = \".\"+i.split('.')[1]+'r.png'\n",
    "    label_name = \".\"+l.split('.')[1]+'r.txt'\n",
    "    image = cv2.imread(i, cv2.IMREAD_ANYCOLOR)\n",
    "    image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(img_name, image)\n",
    "    rl = rotate_yolo_labels_90(l, 640,640)\n",
    "    with open(label_name, 'w') as f:\n",
    "        for item in rl:\n",
    "            f.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6f863-78c7-45b4-b6d5-4551c621ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in dataset:\n",
    "    img_name = \".\"+i.split('.')[1]+'color.png'\n",
    "    label_name = \".\"+l.split('.')[1]+'color.txt'\n",
    "    img = cv2.imread(i, cv2.IMREAD_ANYCOLOR)\n",
    "    img[:,:,1][img[:,:,1] > 180] = img[:,:,1][img[:,:,1] > 180] - 40\n",
    "    img[:,:,2][img[:,:,2] > 180] = img[:,:,2][img[:,:,2] > 180] - 90\n",
    "    cv2.imwrite(img_name, img)\n",
    "    shutil.copy(l, label_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5111e0-258c-4cfa-9b79-c3f7354c92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in dataset:\n",
    "    if 'r' in i.split('/')[-1]:\n",
    "        continue\n",
    "    img_name = \".\"+i.split('.')[1]+'gray.png'\n",
    "    label_name = \".\"+l.split('.')[1]+'gray.txt'\n",
    "    \n",
    "    # print(img_name, label_name)\n",
    "    img = cv2.imread(i, 0)\n",
    "    \n",
    "    cv2.imwrite(img_name, img)\n",
    "    shutil.copy(l, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "915333ef-7550-4cd4-bdf2-b08666a0f417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, l in dataset:\n",
    "    if 'r' in i.split('/')[-1]:\n",
    "        continue\n",
    "    img_name = \".\"+i.split('.')[1]+'color.png'\n",
    "    label_name = \".\"+l.split('.')[1]+'color.txt'\n",
    "    \n",
    "    # print(img_name, label_name)\n",
    "    img = cv2.imread(i, cv2.IMREAD_ANYCOLOR)\n",
    "    img[:,:,1][img[:,:,1] > 180] = img[:,:,1][img[:,:,1] > 180] - 40\n",
    "    img[:,:,2][img[:,:,2] > 180] = img[:,:,2][img[:,:,2] > 180] - 90\n",
    "    cv2.imwrite(img_name, img)\n",
    "    shutil.copy(l, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e29689-5fcb-4b7d-9734-128cf40185f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b20cd6d-efe5-4c21-83c1-d6160b8fb194",
   "metadata": {},
   "source": [
    "## Reference\n",
    " * https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/\n",
    " * https://velog.io/@code_by_hot_pack/%ED%95%9C%EA%B8%80%ED%99%94-How-to-Train-YOLOv8-Object-Detection-on-a-Custom-Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
